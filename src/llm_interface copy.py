# src/llm_interface.py
"""
Interface para LLMs com suporte a mock e providers reais.
"""
import os
import logging
from typing import List, Dict, Any
import random

logger = logging.getLogger(__name__)


class LLMInterface:
    """Interface unificada para diferentes providers de LLM."""

    def __init__(self, provider: str = None):
        """
        Inicializa a interface LLM.

        Args:
            provider: Provider a usar (mock, openai, anthropic)
        """
        self.provider = provider or os.getenv('LLM_PROVIDER', 'mock')
        logger.info(
            f"LLM Interface inicializada com provider: {self.provider}")

        if self.provider == 'openai':
            self._init_openai()
        elif self.provider == 'anthropic':
            self._init_anthropic()
        elif self.provider == 'mock':
            logger.info("Usando LLM Mock para demonstraÃ§Ã£o")
        else:
            raise ValueError(f"Provider desconhecido: {self.provider}")

    def _init_openai(self):
        """Inicializa cliente OpenAI."""
        try:
            import openai
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                raise ValueError("OPENAI_API_KEY nÃ£o configurada")
            openai.api_key = api_key
            self.client = openai
            logger.info("Cliente OpenAI inicializado")
        except ImportError:
            raise ImportError("Instale: pip install openai")

    def _init_anthropic(self):
        """Inicializa cliente Anthropic."""
        try:
            import anthropic
            api_key = os.getenv('ANTHROPIC_API_KEY')
            if not api_key:
                raise ValueError("ANTHROPIC_API_KEY nÃ£o configurada")
            self.client = anthropic.Anthropic(api_key=api_key)
            logger.info("Cliente Anthropic inicializado")
        except ImportError:
            raise ImportError("Instale: pip install anthropic")

    def generate_response(
        self,
        messages: List[Dict[str, str]],
        context: List[Dict[str, Any]] = None,
        temperature: float = None
    ) -> str:
        """
        Gera resposta do LLM.

        Args:
            messages: HistÃ³rico de mensagens
            context: Contexto RAG (chunks relevantes)
            temperature: Temperatura para geraÃ§Ã£o

        Returns:
            Resposta do modelo
        """
        temperature = temperature or float(os.getenv('TEMPERATURE', 0.7))

        if self.provider == 'mock':
            return self._generate_mock_response(messages, context)
        elif self.provider == 'openai':
            return self._generate_openai_response(messages, context, temperature)
        elif self.provider == 'anthropic':
            return self._generate_anthropic_response(messages, context, temperature)

    def _generate_mock_response(
        self,
        messages: List[Dict[str, str]],
        context: List[Dict[str, Any]] = None
    ) -> str:
        """
        Gera resposta mock inteligente baseada no contexto.
        """
        last_message = messages[-1]['content'].lower()

        # Se tem contexto RAG, criar resposta baseada nos dados
        if context and len(context) > 0:
            return self._create_rag_response(context, last_message)

        # Respostas conversacionais mais naturais
        if any(word in last_message for word in ['olÃ¡', 'oi', 'bom dia', 'boa tarde', 'boa noite']):
            greetings = [
                "Oi! Tudo bem? ðŸ˜Š Como posso te ajudar hoje?",
                "OlÃ¡! Espero que esteja tudo bem! Em que posso ser Ãºtil?",
                "Oi! Que bom te ver por aqui! Como posso ajudar?",
                "OlÃ¡! Tudo certo? O que vocÃª gostaria de saber?"
            ]
            import random
            return random.choice(greetings)

        if any(word in last_message for word in ['tudo bem', 'como vocÃª estÃ¡', 'como vai']):
            return "Estou Ã³timo, obrigado por perguntar! ðŸ˜Š E vocÃª, como estÃ¡? Posso ajudar com alguma coisa?"

        if any(word in last_message for word in ['obrigado', 'obrigada', 'valeu', 'obrigadÃ£o']):
            thanks_responses = [
                "Por nada! Fico feliz em ajudar! ðŸ˜Š",
                "De nada! Sempre Ã s ordens!",
                "Imagina! Foi um prazer ajudar!",
                "Por nada! Se precisar de mais alguma coisa, Ã© sÃ³ falar!"
            ]
            import random
            return random.choice(thanks_responses)

        if any(word in last_message for word in ['ajuda', 'help', 'o que vocÃª faz', 'o que voce faz']):
            return """Olha, eu sou um assistente bem versÃ¡til! ðŸ˜Š 

Posso conversar sobre diversos assuntos, mas tenho uma especialidade: **folha de pagamento**! 

Se vocÃª quiser saber sobre:
â€¢ SalÃ¡rios, bÃ´nus e descontos de funcionÃ¡rios
â€¢ Dados de competÃªncia especÃ­fica (ex: marÃ§o/2025)
â€¢ ComparaÃ§Ãµes entre perÃ­odos
â€¢ EstatÃ­sticas gerais

Ã‰ sÃ³ perguntar! Por exemplo: "Qual o salÃ¡rio da Ana em maio?" ou "Mostre os pagamentos do Bruno Lima".

Mas tambÃ©m posso bater um papo sobre outras coisas! O que vocÃª gostaria de saber?"""

        if any(word in last_message for word in ['quem Ã© vocÃª', 'quem voce Ã©', 'seu nome']):
            return "Oi! Eu sou um assistente virtual bem simpÃ¡tico! ðŸ˜Š Posso conversar sobre vÃ¡rias coisas, mas sou especialista em folha de pagamento. E vocÃª, como se chama?"

        if any(word in last_message for word in ['tchau', 'atÃ© logo', 'atÃ© mais', 'bye']):
            goodbye_responses = [
                "Tchau! Foi um prazer conversar! ðŸ˜Š",
                "AtÃ© logo! Volte sempre!",
                "Tchauzinho! Qualquer coisa Ã© sÃ³ chamar!",
                "AtÃ© mais! Foi Ã³timo te ajudar!"
            ]
            import random
            return random.choice(goodbye_responses)

        # Respostas para perguntas sobre folha de pagamento sem contexto especÃ­fico
        if any(word in last_message for word in ['salÃ¡rio', 'salario', 'pagamento', 'folha', 'funcionÃ¡rio', 'funcionario']):
            return "Ah, vocÃª quer saber sobre folha de pagamento! ðŸ˜Š Posso te ajudar com informaÃ§Ãµes sobre salÃ¡rios, bÃ´nus, descontos e datas de pagamento. Tem algum funcionÃ¡rio especÃ­fico em mente? Por exemplo, Ana ou Bruno?"

        # Respostas mais conversacionais para outros assuntos
        if any(word in last_message for word in ['tempo', 'clima', 'chuva', 'sol']):
            return "Opa, falando de tempo! ðŸ˜„ Infelizmente nÃ£o tenho acesso a dados meteorolÃ³gicos em tempo real, mas posso te ajudar com outras informaÃ§Ãµes! Tem alguma pergunta sobre folha de pagamento ou outro assunto?"

        if any(word in last_message for word in ['futebol', 'futebol', 'jogo', 'time']):
            return "Eita, falando de futebol! âš½ Que legal! Infelizmente nÃ£o tenho dados sobre esportes, mas adoraria bater um papo sobre isso! E se quiser saber sobre folha de pagamento, estou aqui tambÃ©m! ðŸ˜Š"

        if any(word in last_message for word in ['comida', 'restaurante', 'receita', 'culinÃ¡ria']):
            return "Nossa, falando de comida! ðŸ¤¤ Que delÃ­cia! Infelizmente nÃ£o tenho receitas, mas posso te ajudar com outras coisas! E se precisar de informaÃ§Ãµes sobre folha de pagamento, Ã© sÃ³ falar!"

        # Resposta padrÃ£o mais conversacional
        return "Hmm, interessante pergunta! ðŸ¤” NÃ£o tenho informaÃ§Ãµes especÃ­ficas sobre isso, mas posso conversar sobre outras coisas! Se quiser saber sobre folha de pagamento, posso te ajudar com dados de salÃ¡rios, bÃ´nus e descontos. O que vocÃª acha?"

    def _create_rag_response(self, context: List[Dict[str, Any]], query: str) -> str:
        """Cria resposta baseada no contexto RAG."""

        # Extrair mÃªs especÃ­fico da pergunta
        target_month = self._extract_target_month(query)

        # Extrair nome do funcionÃ¡rio da pergunta
        target_employee = self._extract_target_employee(query)

        # Filtrar contextos pelo mÃªs e funcionÃ¡rio especÃ­ficos
        filtered_context = context

        # Primeiro filtrar por funcionÃ¡rio se especificado
        if target_employee:
            filtered_context = [
                c for c in filtered_context
                if target_employee.lower() in c['metadata']['name'].lower()
            ]
            # Se nÃ£o encontrou resultados para o funcionÃ¡rio especÃ­fico, usar todos os resultados
            if not filtered_context:
                filtered_context = context
        # Se nÃ£o especificou funcionÃ¡rio, incluir ambos (Ana e Bruno)
        else:
            # Manter todos os resultados para mostrar ambos funcionÃ¡rios
            pass

        # Depois filtrar por mÃªs se especificado
        if target_month:
            filtered_context = [
                c for c in filtered_context if target_month in c['metadata']['competency']]
            # Se nÃ£o encontrou resultados para o mÃªs especÃ­fico, usar todos os resultados
            if not filtered_context:
                filtered_context = context

        # Detectar se Ã© uma pergunta sobre campo especÃ­fico
        is_specific_field_query = self._is_specific_field_query(query)

        # Se Ã© pergunta especÃ­fica sobre campo E especificou funcionÃ¡rio, pegar apenas o melhor resultado
        if is_specific_field_query and target_employee and filtered_context:
            # Pegar apenas o resultado com maior score
            filtered_context = [filtered_context[0]]
        # Se nÃ£o especificou funcionÃ¡rio, organizar por funcionÃ¡rio para mostrar ambos
        elif not target_employee and filtered_context:
            # Agrupar por funcionÃ¡rio e pegar o melhor resultado de cada um
            employee_groups = {}
            for chunk in filtered_context:
                employee_name = chunk['metadata']['name']
                if employee_name not in employee_groups:
                    employee_groups[employee_name] = []
                employee_groups[employee_name].append(chunk)

            # Pegar o melhor resultado de cada funcionÃ¡rio
            filtered_context = []
            for employee_name, chunks in employee_groups.items():
                # Ordenar por score e pegar o melhor
                best_chunk = max(chunks, key=lambda x: x.get('score', 0))
                filtered_context.append(best_chunk)

        # Extrair informaÃ§Ãµes dos chunks filtrados
        responses = []

        for i, chunk in enumerate(filtered_context[:3], 1):
            metadata = chunk['metadata']
            score = chunk.get('score', 0)

            # Formatar dinheiro
            def fmt_money(val):
                return f"R$ {float(val):,.2f}".replace(',', '_').replace('.', ',').replace('_', '.')

            # Formatar data
            def fmt_date(date_str):
                try:
                    from datetime import datetime
                    date_obj = datetime.strptime(
                        str(date_str)[:10], '%Y-%m-%d')
                    return date_obj.strftime('%d/%m/%Y')
                except:
                    return str(date_str)[:10]

            # Criar resposta estruturada e mais conversacional
            response_parts = []

            # IdentificaÃ§Ã£o mais amigÃ¡vel
            employee_name = metadata['name']
            competency = metadata['competency']
            year, month = competency.split('-')
            month_names = {
                '01': 'janeiro', '02': 'fevereiro', '03': 'marÃ§o', '04': 'abril',
                '05': 'maio', '06': 'junho', '07': 'julho', '08': 'agosto',
                '09': 'setembro', '10': 'outubro', '11': 'novembro', '12': 'dezembro'
            }
            month_name = month_names.get(month, month)

            response_parts.append(
                f"**{employee_name}** (ID: {metadata['employee_id']}) - {month_name.title()} de {year}"
            )

            # InformaÃ§Ãµes financeiras baseadas na pergunta com contexto
            if any(word in query for word in ['lÃ­quido', 'liquido', 'net', 'total', 'recebeu', 'recebe']):
                net_pay = fmt_money(metadata['net_pay'])
                response_parts.append(f"ðŸ’° **Pagamento LÃ­quido:** {net_pay}")

            if any(word in query for word in ['salÃ¡rio', 'salario', 'base', 'bruto']):
                base_salary = fmt_money(metadata['base_salary'])
                response_parts.append(f"ðŸ’µ **SalÃ¡rio Base:** {base_salary}")

            if any(word in query for word in ['bÃ´nus', 'bonus', 'adicional']):
                bonus = fmt_money(metadata['bonus'])
                if float(metadata['bonus']) > 0:
                    response_parts.append(f"ðŸŽ **BÃ´nus:** {bonus}")
                else:
                    response_parts.append(
                        f"ðŸŽ **BÃ´nus:** R$ 0,00 (nÃ£o houve bÃ´nus neste mÃªs)")

            if any(word in query for word in ['inss', 'previdÃªncia', 'previdencia']):
                inss = fmt_money(metadata['deductions_inss'])
                response_parts.append(f"ðŸ›ï¸ **Desconto INSS:** {inss}")

            if any(word in query for word in ['irrf', 'imposto', 'renda']):
                irrf = fmt_money(metadata['deductions_irrf'])
                response_parts.append(f"ðŸ“Š **Desconto IRRF:** {irrf}")

            if any(word in query for word in ['benefÃ­cio', 'beneficio', 'vt', 'vr', 'vale']):
                benefits = fmt_money(metadata['benefits_vt_vr'])
                response_parts.append(f"ðŸŽ« **BenefÃ­cios (VT/VR):** {benefits}")

            if any(word in query for word in ['data', 'quando', 'pagamento', 'pago']):
                payment_date = fmt_date(metadata['payment_date'])
                response_parts.append(
                    f"ðŸ“… **Data de Pagamento:** {payment_date}")

            # Se nÃ£o encontrou nenhum filtro especÃ­fico, mostrar resumo completo
            if len(response_parts) == 1:
                response_parts.extend([
                    f"ðŸ’µ **SalÃ¡rio Base:** {fmt_money(metadata['base_salary'])}",
                    f"ðŸŽ **BÃ´nus:** {fmt_money(metadata['bonus'])}",
                    f"ðŸ›ï¸ **Desconto INSS:** {fmt_money(metadata['deductions_inss'])}",
                    f"ðŸ“Š **Desconto IRRF:** {fmt_money(metadata['deductions_irrf'])}",
                    f"ðŸ’° **Pagamento LÃ­quido:** {fmt_money(metadata['net_pay'])}",
                    f"ðŸ“… **Data de Pagamento:** {fmt_date(metadata['payment_date'])}"
                ])

            responses.append('\n'.join(response_parts))

        # Montar resposta final mais conversacional
        if len(responses) == 1:
            final_response = f"Perfeito! Encontrei a informaÃ§Ã£o que vocÃª procurava: ðŸ˜Š\n\n{responses[0]}"
        else:
            # Se nÃ£o especificou funcionÃ¡rio, mostrar informaÃ§Ãµes de ambos
            if not target_employee:
                final_response = f"Aqui estÃ£o as informaÃ§Ãµes de ambos os funcionÃ¡rios: ðŸ˜Š\n\n" + \
                    '\n\n'.join(responses)
            else:
                numbered_responses = [f"{i}. {resp}" for i,
                                      resp in enumerate(responses, 1)]
                final_response = f"Encontrei {len(responses)} resultados para vocÃª: ðŸ˜Š\n\n" + \
                    '\n\n'.join(numbered_responses)

        # Adicionar nota sobre fonte de forma mais amigÃ¡vel
        final_response += f"\n\n_ðŸ“‹ Fonte: dados extraÃ­dos das linhas {', '.join([str(c['row_index']+2) for c in filtered_context[:3]])} do sistema de folha de pagamento._"

        return final_response

    def _extract_target_month(self, query: str) -> str:
        """Extrai o mÃªs especÃ­fico mencionado na pergunta."""
        import re

        query_lower = query.lower()

        # Mapeamento de nomes de meses para cÃ³digos (incluindo abreviaÃ§Ãµes)
        month_mapping = {
            'janeiro': '01', 'jan': '01',
            'fevereiro': '02', 'fev': '02',
            'marÃ§o': '03', 'marco': '03', 'mar': '03',
            'abril': '04', 'abr': '04',
            'maio': '05', 'mai': '05',
            'junho': '06', 'jun': '06',
            'julho': '07', 'jul': '07',
            'agosto': '08', 'ago': '08',
            'setembro': '09', 'set': '09',
            'outubro': '10', 'out': '10',
            'novembro': '11', 'nov': '11',
            'dezembro': '12', 'dez': '12'
        }

        # Procurar por padrÃµes de mÃªs
        # PadrÃ£o 1: "maio", "marÃ§o", "jun", etc.
        for month_name, month_code in month_mapping.items():
            if month_name in query_lower:
                return f"-{month_code}"

        # PadrÃ£o 2: "05", "03", etc. (cÃ³digo numÃ©rico)
        month_pattern = r'\b(0[1-9]|1[0-2])\b'
        month_match = re.search(month_pattern, query)
        if month_match:
            return f"-{month_match.group(1)}"

        # PadrÃ£o 3: "2025-05", "2025-03", etc. (formato completo)
        full_pattern = r'\b(202[0-9])-(0[1-9]|1[0-2])\b'
        full_match = re.search(full_pattern, query)
        if full_match:
            return f"-{full_match.group(2)}"

        return None

    def _extract_target_employee(self, query: str) -> str:
        """Extrai o nome do funcionÃ¡rio mencionado na pergunta."""
        import re

        query_lower = query.lower()

        # Mapeamento de nomes e variaÃ§Ãµes
        employee_mapping = {
            'ana': 'Ana',
            'ana souza': 'Ana Souza',
            'souza': 'Ana Souza',
            'bruno': 'Bruno',
            'bruno lima': 'Bruno Lima',
            'lima': 'Bruno Lima'
        }

        # Procurar por nomes especÃ­ficos
        for name_variation, full_name in employee_mapping.items():
            if name_variation in query_lower:
                return full_name

        # Procurar por padrÃµes mais especÃ­ficos
        name_patterns = [
            r'\b(ana\s+souza)\b',
            r'\b(bruno\s+lima)\b',
            r'\b(ana)\b',
            r'\b(bruno)\b'
        ]

        for pattern in name_patterns:
            match = re.search(pattern, query_lower)
            if match:
                found_name = match.group(1)
                if 'ana' in found_name:
                    return 'Ana Souza' if 'souza' in found_name else 'Ana'
                elif 'bruno' in found_name:
                    return 'Bruno Lima' if 'lima' in found_name else 'Bruno'

        return None

    def _is_specific_field_query(self, query: str) -> bool:
        """Verifica se a pergunta Ã© sobre um campo especÃ­fico."""
        query_lower = query.lower()

        # Palavras que indicam pergunta sobre campo especÃ­fico
        specific_field_indicators = [
            'qual foi o',
            'quanto foi o',
            'quanto Ã© o',
            'qual o',
            'mostre o',
            'mostre os',
            'desconto de',
            'desconto do',
            'bÃ´nus de',
            'bÃ´nus do',
            'salÃ¡rio de',
            'salÃ¡rio do',
            'pagamento de',
            'pagamento do',
            'benefÃ­cio de',
            'benefÃ­cio do',
            'inss de',
            'inss do',
            'irrf de',
            'irrf do'
        ]

        # Verificar se contÃ©m indicadores de campo especÃ­fico
        for indicator in specific_field_indicators:
            if indicator in query_lower:
                return True

        # Verificar se pergunta Ã© sobre um campo especÃ­fico
        specific_fields = [
            'inss', 'previdÃªncia', 'previdencia',
            'irrf', 'imposto', 'renda',
            'bÃ´nus', 'bonus', 'adicional',
            'benefÃ­cio', 'beneficio', 'vt', 'vr', 'vale',
            'salÃ¡rio', 'salario', 'base', 'bruto',
            'lÃ­quido', 'liquido', 'net', 'total'
        ]

        # Se pergunta contÃ©m apenas um campo especÃ­fico, Ã© pergunta especÃ­fica
        field_count = sum(
            1 for field in specific_fields if field in query_lower)
        if field_count == 1:
            return True

        return False

    def _generate_openai_response(
        self,
        messages: List[Dict[str, str]],
        context: List[Dict[str, Any]],
        temperature: float
    ) -> str:
        """Gera resposta usando OpenAI."""
        # Preparar mensagens com contexto
        system_message = self._build_system_prompt(context)

        api_messages = [{"role": "system", "content": system_message}]
        api_messages.extend(messages)

        response = self.client.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=api_messages,
            temperature=temperature
        )

        return response.choices[0].message.content

    def _generate_anthropic_response(
        self,
        messages: List[Dict[str, str]],
        context: List[Dict[str, Any]],
        temperature: float
    ) -> str:
        """Gera resposta usando Anthropic."""
        system_message = self._build_system_prompt(context)

        response = self.client.messages.create(
            model="claude-3-sonnet-20240229",
            max_tokens=1024,
            system=system_message,
            messages=messages,
            temperature=temperature
        )

        return response.content[0].text

    def _build_system_prompt(self, context: List[Dict[str, Any]]) -> str:
        """ConstrÃ³i prompt de sistema com contexto RAG."""
        base_prompt = """VocÃª Ã© um assistente especializado em folha de pagamento.
VocÃª deve responder perguntas sobre dados de folha de pagamento de forma clara e precisa.
Sempre cite a fonte dos dados (employee_id, competÃªncia) quando disponÃ­vel.
Formate valores monetÃ¡rios em reais brasileiros (R$)."""

        if context and len(context) > 0:
            context_text = "\n\nContexto relevante:\n"
            for chunk in context:
                context_text += f"\n{chunk['text']}\n"
            base_prompt += context_text

        return base_prompt
